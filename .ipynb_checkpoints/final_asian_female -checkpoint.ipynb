{
 "cells": [
  {
   "cell_type": "raw",
   "id": "88f8a993",
   "metadata": {},
   "source": [
    "# Facial Recognition Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c85d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53903a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from bing_image_downloader.bing_image_downloader import downloader\n",
    "\n",
    "\n",
    "directory_list = [\n",
    "    './final_asian_female/train/',\n",
    "    './final_asian_female/test/',\n",
    "]\n",
    "\n",
    "# create an initial directory\n",
    "for directory in directory_list:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# function\n",
    "def dataset_split(query, train_cnt):\n",
    "    # create a directory\n",
    "    for directory in directory_list:\n",
    "        if not os.path.isdir(directory + '/' + query):\n",
    "            os.makedirs(directory + '/' + query)\n",
    "    # preparing\n",
    "    cnt = 0\n",
    "    for file_name in os.listdir(query):\n",
    "        if cnt < train_cnt:\n",
    "            print(f'[Train Dataset] {file_name}')\n",
    "            shutil.move(query + '/' + file_name, './final_asian_female/train/' + query + '/' + file_name)\n",
    "        else:\n",
    "            print(f'[Test Dataset] {file_name}')\n",
    "            shutil.move(query + '/' + file_name, './final_asian_female/test/' + query + '/' + file_name)\n",
    "        cnt += 1\n",
    "    shutil.rmtree(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78bf8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Indexing page: 1\n",
      "[Info] Indexed 18 Images on Page 1.\n",
      "===============================================\n",
      "#1 Downloading image (https://img1.kpopmap.com/2019/09/JeenieKim-grid.jpg)\n",
      "#1 The file has been successfully downloaded.\n",
      "#2 Downloading image (http://philnews.ph/wp-content/uploads/2019/05/jennie.jpg)\n",
      "#2 The file has been successfully downloaded.\n",
      "#3 Downloading image (https://1409791524.rsc.cdn77.org/data/images/full/588113/blackpink-jennie.jpeg?w=539&amp;h=397)\n",
      "#3 The file has been successfully downloaded.\n",
      "#4 Downloading image (https://kt.wowkorea.jp/img/album/45/228352/299051.jpg)\n",
      "#4 The file has been successfully downloaded.\n",
      "#5 Downloading image (https://i.pinimg.com/736x/92/46/eb/9246ebbff26c48825597a4bad69587f6.jpg)\n",
      "#5 The file has been successfully downloaded.\n",
      "#6 Downloading image (https://1409791524.rsc.cdn77.org/data/images/full/574622/blackpink-jennie-between-chic-and-lovely-fascinating-visuals.jpeg?w=650)\n",
      "#6 The file has been successfully downloaded.\n",
      "#7 Downloading image (http://img2.yna.co.kr/etc/inner/EN/2018/10/18/AEN20181018007800315_01_i_P4.jpg)\n",
      "#7 The file has been successfully downloaded.\n",
      "#8 Downloading image (https://www.usefulcraft.com/wp-content/uploads/2020/01/lisa-the-painful-wallpaper-36.jpg)\n",
      "[Info] Issue getting: https://www.usefulcraft.com/wp-content/uploads/2020/01/lisa-the-painful-wallpaper-36.jpg\n",
      "[Error] <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "#8 Downloading image (http://www.jebiga.com/wp-content/uploads/2013/06/Emporia_Malmo_Wingardh_Architects_11.jpg)\n",
      "#8 The file has been successfully downloaded.\n",
      "#9 Downloading image (http://images6.fanpop.com/image/photos/41600000/Jennie-jennie-blackpink-41609858-750-1125.jpg)\n",
      "#9 The file has been successfully downloaded.\n",
      "#10 Downloading image (https://pic4.zhimg.com/50/v2-d5b7548dbb8680002c6afa8b8ff64e41_hd.jpg?source=1940ef5c)\n",
      "#10 The file has been successfully downloaded.\n",
      "#11 Downloading image (https://www.usefulcraft.com/wp-content/uploads/2020/01/lisa-the-painful-wallpaper-31.jpg)\n",
      "[Info] Issue getting: https://www.usefulcraft.com/wp-content/uploads/2020/01/lisa-the-painful-wallpaper-31.jpg\n",
      "[Error] <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "#11 Downloading image (https://lh3.googleusercontent.com/MXY_tECTc0poRsuw2Xe44FErcdUSFEy3wLCSxe_3HRemS9KCIrFdHNT68UVmqc-P-3fEhymJ84j1-8Rd-libF5N65dg32uydGF4=w960-rj-nu-e365)\n",
      "#11 The file has been successfully downloaded.\n",
      "#12 Downloading image (https://wallpapercave.com/wp/wp5481336.jpg)\n",
      "#12 The file has been successfully downloaded.\n",
      "#13 Downloading image (https://i.pinimg.com/originals/a5/cf/62/a5cf628ea878df13b2829d9c7f93ce55.jpg)\n",
      "#13 The file has been successfully downloaded.\n",
      "#14 Downloading image (http://images6.fanpop.com/image/photos/41400000/Jennie-for-Cosmopolitan-jennie-blackpink-41437092-609-404.png)\n",
      "#14 The file has been successfully downloaded.\n",
      "#15 Downloading image (https://pic3.zhimg.com/v2-9649572ebef542d73361df03792bc082_r.jpg)\n",
      "#15 The file has been successfully downloaded.\n",
      "#16 Downloading image (http://chazzcreations.com.p8.hostingprod.com/yahoo_site_admin/assets/images/Sir_Robert_Townsend_tomb.29131359_std.jpg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# data for Jennie\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJennie\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdownloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madult_filter_off\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_replace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m dataset_split(query, \u001b[38;5;241m120\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/facial-recognition-project/facial-recognition-project/bing_image_downloader/bing_image_downloader/downloader.py:35\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(query, limit, output_dir, adult_filter_off, force_replace, timeout)\u001b[0m\n\u001b[1;32m     32\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(cwd, output_dir, query))\n\u001b[1;32m     34\u001b[0m bing \u001b[38;5;241m=\u001b[39m Bing(query, limit, output_dir, adult, timeout)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mbing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/facial-recognition-project/facial-recognition-project/bing_image_downloader/bing_image_downloader/bing.py:78\u001b[0m, in \u001b[0;36mBing.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m links:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit:\n\u001b[0;32m---> 78\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===============================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/facial-recognition-project/facial-recognition-project/bing_image_downloader/bing_image_downloader/bing.py:54\u001b[0m, in \u001b[0;36mBing.download_image\u001b[0;34m(self, link)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Download the image\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Downloading image (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_count, link))\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_count\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m The file has been successfully downloaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_count))\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/facial-recognition-project/facial-recognition-project/bing_image_downloader/bing_image_downloader/bing.py:33\u001b[0m, in \u001b[0;36mBing.save_image\u001b[0;34m(self, link, file_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, link, file_path):\n\u001b[1;32m     32\u001b[0m     request \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(link, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m---> 33\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m imghdr\u001b[38;5;241m.\u001b[39mwhat(\u001b[38;5;28;01mNone\u001b[39;00m, image):\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Error] Invalid image, not saving \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(link))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:481\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 481\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:630\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data for Jennie\n",
    "query = 'Jennie Blackpink'\n",
    "downloader.download(query, limit=160,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
    "dataset_split(query, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52228dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for Rosé\n",
    "query = 'Rosé Blackpink'\n",
    "downloader.download(query, limit=160,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
    "dataset_split(query, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52268da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for Jisoo\n",
    "query = 'Jisoo Blackpink'\n",
    "downloader.download(query, limit=160,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
    "dataset_split(query, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60299665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms_train dataset\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(), # augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = './final_asian_female'\n",
    "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n",
    "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), transforms_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "print('size of training dataset:', len(train_datasets))\n",
    "print('size of validating dataset:', len(test_datasets))\n",
    "\n",
    "class_names = train_datasets.classes\n",
    "print('class:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(input, title):\n",
    "    # convert torch.Tensor to numpy\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    input = std * input + mean\n",
    "    input = np.clip(input, 0, 1)\n",
    "    # print image\n",
    "    plt.imshow(input)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# call training data in batches\n",
    "iterator = iter(train_dataloader)\n",
    "\n",
    "# visualize the batches\n",
    "inputs, classes = next(iterator)\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "# transfer learning\n",
    "model.fc = nn.Linear(num_features, 3)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a91014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "\n",
    "# repeat the number of epoch\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.\n",
    "    train_corrects = 0\n",
    "\n",
    "    # call training data in batches\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = train_loss / len(train_datasets)\n",
    "    epoch_acc = train_corrects / len(train_datasets) * 100.\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0.\n",
    "    valid_corrects = 0\n",
    "    \n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        valid_loss += loss.item() * inputs.size(0)\n",
    "        valid_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss2 = valid_loss / len(test_datasets)\n",
    "    epoch_acc2 = valid_corrects / len(test_datasets) * 100.    \n",
    "    # print the result\n",
    "    print('#{} Loss: {:.4f} Valid Loss: {:.4f} Acc: {:.4f}% Valid Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_loss2, epoch_acc, epoch_acc2, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some results\n",
    "print(f'[Prediction: {class_names[preds[2]]}] (Actual: {class_names[labels.data[2]]})')\n",
    "imshow(inputs.cpu().data[2], title='Prediction: ' + class_names[preds[2]])\n",
    "print(f'[Prediction: {class_names[preds[9]]}] (Actual: {class_names[labels.data[9]]})')\n",
    "imshow(inputs.cpu().data[9], title='Prediction: ' + class_names[preds[9]])\n",
    "print(f'[Prediction: {class_names[preds[10]]}] (Actual: {class_names[labels.data[10]]})')\n",
    "imshow(inputs.cpu().data[10], title='Prediction: ' + class_names[preds[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a03c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
